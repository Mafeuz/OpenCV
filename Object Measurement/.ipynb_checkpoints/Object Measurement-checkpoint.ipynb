{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import copy\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Measurement ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on Murtaza's Workshop Video: https://www.youtube.com/watch?v=tk9war7_y0Q&pp=sAQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Contours(work_img, canny_thresh=[100,100], dil=3, ero=2, minArea = 1000, filter = 0, draw = False):\n",
    "    \n",
    "    img = work_img.copy()\n",
    "    \n",
    "    # Canny Processing:\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur_img = cv2.GaussianBlur(gray_img, (5,5), 1)\n",
    "    canny_img = cv2.Canny(blur_img, canny_thresh[0], canny_thresh[1])\n",
    "    \n",
    "    kernel = np.ones((2,2))\n",
    "    \n",
    "    img_dilation = cv2.dilate(canny_img, kernel, iterations = dil)\n",
    "    img_thresh = cv2.erode(img_dilation, kernel, iterations = ero)\n",
    "\n",
    "    ################################################################################################################\n",
    "    # Contour Filtering:\n",
    "    contours, hiearchy = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    finalContours = []\n",
    "    \n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        \n",
    "        if (area > minArea):\n",
    "            \n",
    "            # Get contour perimiter:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            # Get contour corner points:\n",
    "            approx = cv2.approxPolyDP(c, 0.02*peri, True)\n",
    "            bbox = cv2.boundingRect(approx)\n",
    "            \n",
    "            # Filtering by number of Corner Points:\n",
    "            if (filter > 0):\n",
    "                if (len(approx) == filter):\n",
    "                    finalContours.append([len(approx), area, approx, bbox, c])\n",
    "                \n",
    "                if (len(approx) > filter+2) or (len(approx) == 3):\n",
    "                    # If the object does not have the number of corners equal to filter, \n",
    "                    # body centroid detection will be used to generate a rectangle around\n",
    "                    # the object and it's corner points will be passed forward.\n",
    "                    \n",
    "                    M = cv2.moments(c)\n",
    "\n",
    "                    # calculate x,y coordinate of centroid\n",
    "                    if M[\"m00\"] != 0:\n",
    "                        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "                        # Get contour extreme points:\n",
    "                        extLeft = c[c[:, :, 0].argmin()][0]\n",
    "                        extRight = c[c[:, :, 0].argmax()][0]\n",
    "                        extTop = c[c[:, :, 1].argmin()][0]\n",
    "                        extBot = c[c[:, :, 1].argmax()][0]\n",
    "\n",
    "                        Obj_W = extRight[0] - extLeft[0]\n",
    "                        Obj_H = extBot[1] - extTop[1]\n",
    "\n",
    "                        # Our Corner points for the rectangle:\n",
    "                        approx = np.array([[[(cX -Obj_W//2), (cY -Obj_H//2)]],\n",
    "                                  [[(cX +Obj_W//2), (cY -Obj_H//2)]],\n",
    "                                  [[(cX +Obj_W//2), (cY +Obj_H//2)]],\n",
    "                                  [[(cX -Obj_W//2), (cY +Obj_H//2)]]])\n",
    "\n",
    "                        bbox = cv2.boundingRect(approx)\n",
    "                        finalContours.append([len(approx), area, approx, bbox, c])\n",
    "                        \n",
    "            else:\n",
    "                finalContours.append([len(approx), area, approx, bbox, c])\n",
    "    \n",
    "    # Contour Sort by Area:\n",
    "    finalContours = sorted(finalContours, key = lambda x:x[1], reverse = True)\n",
    "    \n",
    "    # Draw if required:\n",
    "    if (draw == True):\n",
    "        for con in finalContours:\n",
    "            cv2.drawContours(img, con[4], -1, (0,0,255), 3)\n",
    "            \n",
    "    return img, img_thresh, finalContours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_points(myPoints):\n",
    "    \n",
    "    myNewPoints = np.zeros_like(myPoints)\n",
    "    myPoints = myPoints.reshape((4,2))\n",
    "    \n",
    "    add = myPoints.sum(1)\n",
    "    myNewPoints[0] = myPoints[np.argmin(add)]\n",
    "    myNewPoints[3] = myPoints[np.argmax(add)]\n",
    "    \n",
    "    diff = np.diff(myPoints, axis = 1)\n",
    "    myNewPoints[1] = myPoints[np.argmin(diff)]\n",
    "    myNewPoints[2] = myPoints[np.argmax(diff)]\n",
    "    \n",
    "    return myNewPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Img_Warping(img, points, w, h, pad=20):\n",
    "    points = reorder_points(points)\n",
    "    pts1 = np.float32(points)\n",
    "    pts2 = np.float32([[0,0],[w,0],[0,h],[w,h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    img_warp = cv2.warpPerspective(img, matrix, (w,h))\n",
    "    img_warp = img_warp[pad:img_warp.shape[0]-pad, pad:img_warp.shape[1]-pad]\n",
    "    \n",
    "    return img_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance(pts1, pts2):\n",
    "    return sqrt((pts2[0]-pts1[0])**2 + (pts2[1]-pts1[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Draw_Perspective_Points(img, p_points, text=False):\n",
    "    \n",
    "    # Draw corner points for perspective adjust:\n",
    "    cv2.circle(img, (p_points[0,0]), 5, (255, 0, 0), -1)\n",
    "    cv2.circle(img, (p_points[1,0]), 5, (255, 0, 0), -1)\n",
    "    cv2.circle(img, (p_points[2,0]), 5, (255, 0, 0), -1)\n",
    "    cv2.circle(img, (p_points[3,0]), 5, (255, 0, 0), -1)\n",
    "    \n",
    "    if text:\n",
    "        cv2.putText(img, \"P1\", (p_points[0,0]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 155), 2)\n",
    "        cv2.putText(img, \"P2\", (p_points[1,0]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 155), 2)\n",
    "        cv2.putText(img, \"P4\", (p_points[3,0]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 155), 2)\n",
    "        cv2.putText(img, \"P3\", (p_points[2,0]+10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 155), 2)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Object_Measurement(frame, img_scale, Ref_Object_W, Ref_Object_H, unit_pixel, show_img_canny = False):   \n",
    "\n",
    "    img_with_conts, conts = Get_Contours(frame, filter = 4, minArea = 10000, dil = 2, ero = 1, show_canny = False, draw=False)\n",
    "\n",
    "    # Get 4 corner points to WARP:\n",
    "    if len(conts) != 0:\n",
    "        \n",
    "        success = True\n",
    "        \n",
    "        # Perspective Warping based on corner points of the biggest contour(which should be the reference object):\n",
    "        biggest_cont_corners = conts[0][2]\n",
    "        img_warped = Img_Warping(frame, biggest_cont_corners, Ref_Object_W, Ref_Object_H, pad=25)\n",
    "\n",
    "        # After Warping Get New Objects Contours:\n",
    "        img_with_conts2, conts2 = Get_Contours(img_warped, filter = 4, minArea = 500, dil = 3, ero = 1, canny_thresh=[30,30], show_canny = show_img_canny, draw=False)\n",
    "        \n",
    "        if len(conts2) != 0:\n",
    "            for obj in conts2:\n",
    "                \n",
    "                cv2.polylines(img_warped, [obj[2]], True, (255,0,0), 2)\n",
    "                new_points = reorder_points(obj[2])\n",
    "\n",
    "                #img_warped = Draw_Perspective_Points(img_warped, new_points, text=False)\n",
    "\n",
    "                d1 = (round(find_distance(new_points[0][0]//img_scale/unit_pixel, new_points[1][0]//img_scale/unit_pixel)))\n",
    "                d2 = (round(find_distance(new_points[0][0]//img_scale/unit_pixel, new_points[2][0]//img_scale/unit_pixel)))\n",
    "\n",
    "                d3 = (round(find_distance(new_points[2][0]//img_scale/unit_pixel, new_points[3][0]//img_scale/unit_pixel)))\n",
    "                d4 = (round(find_distance(new_points[1][0]//img_scale/unit_pixel, new_points[3][0]//img_scale/unit_pixel)))\n",
    "\n",
    "                # Write Distances:\n",
    "                cv2.putText(img_warped, \"d1 = {}\".format(d1), (new_points[0][0] + (new_points[1][0] - new_points[0][0])//2), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 155), 1)\n",
    "                cv2.putText(img_warped, \"d2 = {}\".format(d2), (new_points[0][0] + (new_points[2][0] - new_points[0][0])//2), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 155), 1)\n",
    "                cv2.putText(img_warped, \"d3 = {}\".format(d3), (new_points[2][0] + (new_points[3][0] - new_points[2][0])//2), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 155), 1)\n",
    "                cv2.putText(img_warped, \"d4 = {}\".format(d4), (new_points[1][0] + (new_points[3][0] - new_points[1][0])//2), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 155), 1)\n",
    "    \n",
    "    else:\n",
    "        success = False\n",
    "        img_warped = frame.copy()\n",
    "        \n",
    "    return success, img_warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference Settings:\n",
    "img_scale = 1\n",
    "Ref_Object_W = 350*img_scale # mm\n",
    "Ref_Object_H = 600*img_scale # mm\n",
    "unit_pixel = 10 # 10 factor for cm\n",
    "\n",
    "cap = cv2.VideoCapture('http://192.168.0.106:8080/video')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        print('Server OFF')\n",
    "        break\n",
    "        \n",
    "    frame = cv2.resize(frame, (0, 0), None, 0.8, 0.8)\n",
    "    frame = cv2.flip(frame, 0)\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Keyboard Controls:\n",
    "    \n",
    "    key = cv2.waitKey(1) or 0xff   \n",
    "        \n",
    "    if key == ord('k'):\n",
    "        break\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    success, frame = Object_Measurement(frame, img_scale, Ref_Object_W, Ref_Object_H, unit_pixel, show_img_canny = True)\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    FPS = 1/(end_time - start_time + 0.0001)\n",
    "    \n",
    "    if FPS < 70: # preventing internet connection problems crazy values to pop up.\n",
    "        cv2.putText(frame, \"FPS: {}\".format(FPS), (30,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    if success:\n",
    "        cv2.imshow(\"Camera\", frame)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
