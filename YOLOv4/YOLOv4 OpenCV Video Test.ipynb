{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV + YOLOv4(tiny-coco) for Object Detection Video ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_net(net_weights_path, net_config_path):\n",
    "    # Config net using cv2 (needs weights and config files)\n",
    "    net = cv2.dnn.readNet(net_config_path, net_weights_path)\n",
    "    output_layers = net.getLayerNames()\n",
    "    output_layers  = [output_layers [i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return net, output_layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLO_processing(img, net, output_layers):\n",
    "    # Pass img/frame, net and output layers get output:\n",
    "\n",
    "    start= time.time()\n",
    "\n",
    "    # Modify img to input format:\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416), swapRB = True, crop = False)\n",
    "\n",
    "    # Pass to net:\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    yolo_process_time = end - start\n",
    "    \n",
    "    return layer_outputs, yolo_process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLO_detections(img, net, output_layers, labels, des_det, colors, threshold = 0.5, threshold_NMS = 0.3):\n",
    "    # Output format:\n",
    "    # (pc, bx, by, bh, bw, .... class_preds)\n",
    "\n",
    "    (H, W) = img.shape[:2]\n",
    "    \n",
    "    layer_outputs, yolo_process_time = YOLO_processing(img, net, output_layers)\n",
    "    \n",
    "    boxes = []\n",
    "    confidence = []\n",
    "    IDclasses = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classeID = np.argmax(scores) # Get class with more probability\n",
    "            trust = scores[classeID]\n",
    "            if trust > threshold:\n",
    "                # reescale position values:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype('int')\n",
    "\n",
    "                # box structure:\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidence.append(float(trust))\n",
    "                IDclasses.append(classeID)\n",
    "    \n",
    "    # Filtering detected object boxes with NMS (Non-maxima Suppression):\n",
    "    objs = cv2.dnn.NMSBoxes(boxes, confidence, threshold, threshold_NMS)\n",
    "    \n",
    "    # Draw Desired Boxes:\n",
    "    if len(objs) > 0:\n",
    "        for i in objs.flatten():\n",
    "            # Filter Desired Object Classes to detect:\n",
    "            if labels[IDclasses[i]] in des_det:\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "    \n",
    "                # get obj class color:\n",
    "                color = [int(c) for c in colors[IDclasses[i]]]\n",
    "                text = \"{}: {:.4f}\".format(labels[IDclasses[i]], confidence[i])\n",
    "                \n",
    "                # add litle background to class name info:\n",
    "                backg = np.full((img.shape), (0,0,0), dtype=np.uint8)\n",
    "                cv2.putText(backg, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n",
    "                fx,fy,fw,fh = cv2.boundingRect(backg[:,:,2])\n",
    "                \n",
    "                # Draw obj bbox:\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2) \n",
    "                cv2.rectangle(img, (fx, fy), (fx + fw, fy + fh), color, -1) \n",
    "                cv2.rectangle(img, (fx, fy), (fx + fw, fy + fh), color, 3) \n",
    "                cv2.putText(img, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)              \n",
    "    \n",
    "    return img, boxes, confidence, yolo_process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection and Classification: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tiny Yolo Info: \n",
    "## Tiny Yolo: https://github.com/AlexeyAB/darknet\n",
    "## https://githubmemory.com/repo/Tossy0423/yolov4-for-darknet_ros/issues/7\n",
    "## Using Tiny-Yolo for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Yolo Net Architecture Weights and Configuration:\n",
    "net_weights_path = 'weights/yolov4-tiny.weights'\n",
    "net_config_path = 'cfgs/yolov4-tiny.cfg'\n",
    "net, output_layers = config_net(net_weights_path, net_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of Layers: 2\n",
      "['yolo_30', 'yolo_37']\n"
     ]
    }
   ],
   "source": [
    "# Check structure:\n",
    "print('Total of Layers: ' + str(len(output_layers)))\n",
    "print(output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# Get coco class labels:\n",
    "coco_labels = open('cfgs/coco.names').read().strip().split('\\n')\n",
    "print(coco_labels)\n",
    "print(len(coco_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random colors for bboxes:\n",
    "np.random.seed(0)\n",
    "colors = np.random.randint(0, 255, size=(len(coco_labels), 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define necessary variables:\n",
    "threshold = 0.5\n",
    "threshold_NMS = 0.3\n",
    "desired_detections = ['car', 'motorbike', 'bicycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Video:\n",
    "cap = cv2.VideoCapture('C:/Users/Mafeus/Desktop/Git_Repos/OpenCV/Testing Grounds/ztest_media/street_sample_video.mp4')\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "        \n",
    "    frame = cv2.resize(frame, (600,500))\n",
    "    \n",
    "    # Keyboard Controls:\n",
    "    \n",
    "    key = cv2.waitKey(1) or 0xff   \n",
    "        \n",
    "    if key == ord('k'):\n",
    "        break\n",
    "    \n",
    "    #########################################################################################################################\n",
    "    \n",
    "    frame, boxes, confidence, yolo_process_time = YOLO_detections(frame, net, output_layers, coco_labels, desired_detections, \n",
    "                                                                    colors, threshold, threshold_NMS)\n",
    "    \n",
    "    #########################################################################################################################\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    frame_time = (end - start) + 0.0001\n",
    "    fps = np.floor(1/frame_time)\n",
    "        \n",
    "    if (fps > video_fps):\n",
    "        time.sleep(1/video_fps)\n",
    "        fps = video_fps\n",
    "            \n",
    "    cv2.putText(frame, \"FPS: {}\".format(fps), (30,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Output\", frame)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
