{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CV TESTING GROUNDS ##\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIMAGE_RESOLUTION = (1280, 1024)\\nZOOM_LEVEL = 0\\nRESOLUTION_MAX_ZOOM = 0.16 # microns/pixel\\nRESOLUTION_MIN_ZOOM = 1.90 # microns/pixel\\nFIELD_OF_VIEW_MAX_ZOOM =  (0.38, 0.24) # mm\\nFIELD_OF_VIEW_MIN_ZOOM =  (2.4, 1.9) # mm\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control Variables\n",
    "\n",
    "VIDEO = \"SampleVideo_1280x720_2mb.mp4\"\n",
    "IMAGE_RESOLUTION_RESIZE = (600,520)\n",
    "\n",
    "bright_threshold = 30\n",
    "focus_threshold = 5000\n",
    "  \n",
    "# define color boundaries to filtering highlight (BGR)\n",
    "color_filter_boundaries = [([120, 120, 120], [250, 250, 250])]\n",
    "\n",
    "TRACKER = \"CSRT\"\n",
    "BRIGHT_DETECTION = 0\n",
    "FOCUS_DETECTION = 0\n",
    "COLOR_FILTER = 1\n",
    "WATCH_FILTER = 1\n",
    "CANNY = 1\n",
    "WATCH_CANNY = 1\n",
    "TRACK_CANNY = 1\n",
    "EROSION = 1\n",
    "DILATION = 0\n",
    "BODY_CENTROID = 0\n",
    "ELLIPSE_DETECTION = 0\n",
    "SPLIT_FOCUS = 0\n",
    "SHOW_GRID = 0\n",
    "GRID_SIZE = 30\n",
    "SHOW_FPS = 1\n",
    "\n",
    "# Camera Properties\n",
    "\n",
    "'''\n",
    "IMAGE_RESOLUTION = (1280, 1024)\n",
    "ZOOM_LEVEL = 0\n",
    "RESOLUTION_MAX_ZOOM = 0.16 # microns/pixel\n",
    "RESOLUTION_MIN_ZOOM = 1.90 # microns/pixel\n",
    "FIELD_OF_VIEW_MAX_ZOOM =  (0.38, 0.24) # mm\n",
    "FIELD_OF_VIEW_MIN_ZOOM =  (2.4, 1.9) # mm\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bright_detection(frame, gray_frame, bright_Threshold):\n",
    "\n",
    "    blur = cv2.blur(gray_frame , (5, 5))\n",
    "\n",
    "    a, b, c, d = cv2.mean(blur)\n",
    "\n",
    "    if a > bright_Threshold:\n",
    "        cv2.putText(frame, \"BRIGHT\", (470, 15),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 80, 80), 1)\n",
    "        \n",
    "    else:\n",
    "        cv2.putText(frame, \"DARK\", (470, 15),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 80, 80), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_detection(frame, gray_frame, focus_threshold):\n",
    "    \n",
    "    # Focus Analyser Using Scharr Function\n",
    "    focus = cv2.Scharr(gray_frame, cv2.CV_64F, 1, 0).var() # Apply Scharr;\n",
    "        \n",
    "    # Print if is Focused;\n",
    "    if (focus > focus_threshold):\n",
    "        cv2.putText(frame, \"FOCUSED\", (470, 40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        return 1\n",
    "\n",
    "    # Print if not Focused;\n",
    "    else:\n",
    "        cv2.putText(frame, \"NO FOCUS\", (470, 40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_focus(gray_frame):\n",
    "    \n",
    "    h = int(gray_frame.shape[0]/2)\n",
    "    w = int(gray_frame.shape[1]/2)\n",
    "        \n",
    "    (y1, x1, y2, x2, y3, x3, y4, x4) = (0, 0, 0, w, h, 0, h, w)\n",
    "\n",
    "    upleft_quad = gray_frame[y1:y1+h, x1:x1+w]\n",
    "    upright_quad = gray_frame[y2:y2+h, x2:x2+w]\n",
    "    downleft_quad = gray_frame[y3:y3+h, x3:x3+w]\n",
    "    downright_quad = gray_frame[y4:y4+h, x4:x4+w]\n",
    "\n",
    "    focus1 = cv2.Scharr(upleft_quad, cv2.CV_64F, 1, 0).var() # Apply Scharr;\n",
    "    focus2 = cv2.Scharr(upright_quad, cv2.CV_64F, 1, 0).var() # Apply Scharr;\n",
    "    focus3 = cv2.Scharr(downleft_quad, cv2.CV_64F, 1, 0).var() # Apply Scharr;\n",
    "    focus4 = cv2.Scharr(downright_quad, cv2.CV_64F, 1, 0).var() # Apply Scharr;\n",
    "\n",
    "    cv2.putText(upleft_quad, \"Focus: {}\".format(focus1), (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1) \n",
    "    cv2.putText(upright_quad, \"Focus: {}\".format(focus2), (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1) \n",
    "    cv2.putText(downleft_quad, \"Focus: {}\".format(focus3), (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1) \n",
    "    cv2.putText(downright_quad, \"Focus: {}\".format(focus4), (20, 20),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1) \n",
    "\n",
    "    cv2.imshow(\"Up Left Quad\", upleft_quad)\n",
    "    cv2.imshow(\"Up Right Quad\", upright_quad)\n",
    "    cv2.imshow(\"Down Left Quad\", downleft_quad)\n",
    "    cv2.imshow(\"Down Right Quad\", downright_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_filtering(frame, boundaries):\n",
    "\n",
    "    # loop over the boundaries\n",
    "    for (lower, upper) in boundaries:\n",
    "\n",
    "        # create NumPy arrays from the boundaries\n",
    "        lower = np.array(lower, dtype = \"uint8\") # Lower color limit\n",
    "        upper = np.array(upper, dtype = \"uint8\") # Upper color limit\n",
    "\n",
    "        mask = cv2.inRange(frame, lower, upper) # mask with objects in range of lower to upper\n",
    "        output_filter = cv2.bitwise_and(frame, frame, mask = mask) # output = roiselect & mask\n",
    "        output_filter[np.where((output_filter == [0,0,0]).all(axis = 2))] = [255,255,255] # the background is black, turn it to white\n",
    "        output_filter[np.where((output_filter != [255,255,255]).all(axis = 2))] = [0,0,0] # turn everything that is not white to black\n",
    "        output_filter = cv2.cvtColor(output_filter,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        output_filter = cv2.bitwise_not(output_filter)\n",
    "        \n",
    "    return output_filter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_custom(gray_frame, erosion, dilation):\n",
    "    \n",
    "    if (erosion > 0):\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        gray_frame = cv2.erode(gray_frame,kernel,iterations = erosion)\n",
    "           \n",
    "    blurred = cv2.GaussianBlur(gray_frame, (3, 3), 1)\n",
    "    frame_canny = cv2.Canny(blurred, 10, 10)\n",
    "        \n",
    "    if (dilation > 0):\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        frame_canny = cv2.dilate(frame_canny,kernel,iterations = dilation)\n",
    "        frame_canny = cv2.bitwise_not(frame_canny)\n",
    "        \n",
    "    return frame_canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_centroid(frame, gray_frame, canny_on, frame_canny):\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(gray_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if (canny_on !=0):\n",
    "        contours, hierarchy = cv2.findContours(frame_canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for c in contours:\n",
    "        # calculate moments for each contour\n",
    "        M = cv2.moments(c)\n",
    "    \n",
    "        # calculate x,y coordinate of centroid\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroidX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            centroidY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            area = cv2.contourArea(c)\n",
    "            cv2.circle(frame, (centroidX, centroidY), 3, (255, 0, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ellipse(frame, gray_frame, canny_on, frame_canny):\n",
    "    \n",
    "        contours, hierarchy = cv2.findContours(gray_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        if (CANNY !=0):\n",
    "            contours, hierarchy = cv2.findContours(frame_canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        if len(contours) != 0:\n",
    "                for c in contours:\n",
    "                    if (cv2.contourArea(c) > 100):\n",
    "                        ellipse = cv2.fitEllipse(c)\n",
    "                        (x, y), (MA, ma), angle = ellipse\n",
    "                        EllipseArea = (PI / 4 * MA * ma)\n",
    "                        if (350 > x > 250):\n",
    "                            if ((MA*1.7 > ma > MA*0.3) or (ma*1.7 > MA > ma*0.3)) & (fig_area > EllipseArea > fig_area*0.15):\n",
    "\n",
    "                                M = cv2.moments(c)\n",
    "\n",
    "                                # calculate x,y coordinate of centroid\n",
    "                                if M[\"m00\"] != 0:\n",
    "                                    centroidX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                                    centroidY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                                    area = cv2.contourArea(c)\n",
    "                                    \n",
    "                                if ((x - 6) < centroidX < (x + 6)) & ((y - 6) < centroidY < (y + 6)):\n",
    "                                    \n",
    "                                    cv2.ellipse(frame,ellipse,(255,200,0),2)\n",
    "                                    cv2.circle(frame, (int(x), int(y)), 3, (255, 200, 0), -1)\n",
    "                                    cv2.putText(frame, \"{:.2f}\".format(angle), (int(x)+3, int(y)+3),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 0), 1)\n",
    "                                    cv2.circle(frame, (centroidX, centroidY), 3, (255, 0, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Setup:\n",
    "\n",
    "# Create MultiTracker object\n",
    "Tracker = cv2.MultiTracker_create()\n",
    "\n",
    "# ROI State Variable\n",
    "TRACKING_ON = 0\n",
    "\n",
    "PI = np.pi\n",
    "\n",
    "# Select Desired Video\n",
    "video = cv2.VideoCapture(VIDEO)\n",
    "\n",
    "# Video stream loop:\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    if not ret: # Break the loop if no video is load.\n",
    "        break\n",
    "    \n",
    "    frame = cv2.resize(frame,(IMAGE_RESOLUTION_RESIZE))\n",
    "    fig_area = (frame.shape[0]*frame.shape[1])\n",
    "    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #**************************************************************************************************************************\n",
    "    #**********************************************/Bright Detection/**********************************************************\n",
    "    if (BRIGHT_DETECTION == 1):\n",
    "        \n",
    "        bright_detection(frame, gray_frame, bright_threshold)\n",
    "      \n",
    "    #**************************************************************************************************************************\n",
    "    #**********************************************/Focus Detection/***********************************************************\n",
    "    \n",
    "    # Focus Variance threshold, must be calibrated using a focused sample;\n",
    "    \n",
    "    FOCUS = 1\n",
    "    \n",
    "    if (FOCUS_DETECTION == 1):\n",
    "    \n",
    "        FOCUS = focus_detection(frame, gray_frame, focus_threshold)\n",
    "         \n",
    "    #**************************************************************************************************************************\n",
    "    #**************************************/Split in Quadrants Focus Detection/************************************************ \n",
    "    if (SPLIT_FOCUS == 1):\n",
    "        \n",
    "        split_focus(gray_frame)\n",
    "\n",
    "    #**************************************************************************************************************************\n",
    "    #********************************************/Color Filter Application/****************************************************\n",
    "    if (COLOR_FILTER == 1):\n",
    "        \n",
    "        gray_frame = color_filtering(frame, color_filter_boundaries)\n",
    "        output_filter_show = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "    #**************************************************************************************************************************\n",
    "    #**********************************************/Canny Application/*********************************************************\n",
    "    if (CANNY == 1):\n",
    "        \n",
    "        frame_canny = canny_custom(gray_frame, EROSION, DILATION)\n",
    "        frame_canny_show = cv2.cvtColor(frame_canny, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    #**************************************************************************************************************************\n",
    "    #**********************************************/Ellipse Detection/*********************************************************\n",
    "    if (ELLIPSE_DETECTION == 1) & (FOCUS == 1):\n",
    "\n",
    "        if (CANNY == 0):\n",
    "            find_ellipse(frame, gray_frame, canny_on, frame_canny)\n",
    "        \n",
    "        if (CANNY == 1):\n",
    "            find_ellipse(frame, gray_frame, canny_on, frame_canny)\n",
    "\n",
    "    #**************************************************************************************************************************\n",
    "    #**********************************************/Body Centroid/*************************************************************                   \n",
    "    if (BODY_CENTROID == 1):\n",
    "        \n",
    "        if (CANNY == 0):\n",
    "            object_centroid(frame, gray_frame, CANNY, gray_frame)\n",
    "        \n",
    "        if (CANNY == 1):\n",
    "            object_centroid(frame, gray_frame, CANNY, frame_canny)\n",
    "                      \n",
    "    #**************************************************************************************************************************\n",
    "    #**********************************************/Selected ROI Tracker/******************************************************\n",
    "    \n",
    "    # Press P to Select the Region of Interest and Track it using CSRT Tracker.\n",
    "    # Press K after a tracking start to stop it.\n",
    "    # Press Q to break the video stream and close windows.\n",
    "    \n",
    "    key = cv2.waitKey(1) or 0xff\n",
    "    \n",
    "    if (FOCUS != 1):\n",
    "        cv2.putText(frame, \"Not ready to Track, adjust focus.\", (100, 510),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "    if (FOCUS == 1) & (TRACKING_ON == 0):\n",
    "        cv2.putText(frame, \"Ready to Track, press P to select the Region of Interest.\", (100, 510),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    #************************************* PRESS Q TO CLOSE STREAM ************************************************************\n",
    "    #**************************************************************************************************************************\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    #**************************************************************************************************************************\n",
    "    \n",
    "    #************************************* PRESS P TO SELECT TRACKING OBJECT **************************************************\n",
    "    #**************************************************************************************************************************\n",
    "    if key == ord('p'):\n",
    "        \n",
    "         if (FOCUS == 1) & (TRACKING_ON == 0):\n",
    "            cv2.putText(frame, \"Ready to Track, press P to select the Region of Interest.\", (100, 510),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 80, 80), 1)\n",
    "\n",
    "            if (TRACK_CANNY == 0):\n",
    "                TRACKING_ON = 1\n",
    "                r = cv2.selectROI(frame)\n",
    "\n",
    "                # Add Tracker\n",
    "                Tracker.add(cv2.TrackerCSRT_create(), frame, r)\n",
    "               \n",
    "            if (TRACK_CANNY == 1):\n",
    "                TRACKING_ON = 1\n",
    "                r = cv2.selectROI(frame_canny)\n",
    "\n",
    "                # Add Tracker\n",
    "                Tracker.add(cv2.TrackerCSRT_create(), frame_canny, r)\n",
    "            \n",
    "    #**************************************************************************************************************************\n",
    "    #**************************************************************************************************************************\n",
    "    \n",
    "    if (TRACKING_ON == 1):\n",
    "        \n",
    "        # get updated location of objects in subsequent frames\n",
    "        success, boxes = Tracker.update(frame)\n",
    "\n",
    "        # draw tracked objects\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            p1 = (int(newbox[0]), int(newbox[1]))\n",
    "            p2 = (int(newbox[0] + newbox[2]), int(newbox[1] + newbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 0, 255), 2, 1)\n",
    "            cX = int(p1[0] + (p2[0]-p1[0])/2)\n",
    "            cY = int(p1[1] + (p2[1]-p1[1])/2)\n",
    "            cv2.circle(frame, (cX, cY), 3, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"CSRT\", (30,30), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            cv2.putText(frame, \"Object Centroid\", (30,60), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            cv2.putText(frame, \"X {}\".format(cX), (30, 90),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)   \n",
    "            cv2.putText(frame, \"Y {}\".format(cY), (30, 120),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            \n",
    "            CenterX = frame.shape[1]/2 \n",
    "            CenterY = frame.shape[0]/2\n",
    "            \n",
    "            cv2.putText(frame, \"Image Center\", (470,60), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            cv2.putText(frame, \"X {}\".format(CenterX), (470, 90),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)   \n",
    "            cv2.putText(frame, \"Y {}\".format(CenterY), (470, 120),cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)\n",
    "            \n",
    "            #******************************************************************************************************************\n",
    "            #**************************************/ Centralization Checking /*************************************************\n",
    "            PosBand = 6\n",
    "\n",
    "            DX = (CenterX - cX)\n",
    "            DY = (CenterY - cY)\n",
    "\n",
    "            cv2.putText(frame, \"DELTA X {}\".format(DX), (470, 270),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, \"DELTA Y {}\".format(DY), (470, 300),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, \"Tolerance: {}\".format(PosBand), (470, 330),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Check if is Centralized\n",
    "\n",
    "            if (cX > (CenterX - PosBand)) & (cX < (CenterX + PosBand)):\n",
    "                cv2.putText(frame, \"Centralized X\", (470, 200),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            if (cY > (CenterY - PosBand)) & (cY < (CenterY + PosBand)):\n",
    "                cv2.putText(frame, \"Centralized y\", (470, 230),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                \n",
    "    #**************************************************************************************************************************\n",
    "    #**************************************************************************************************************************\n",
    "\n",
    "    #************************************* PRESS K TO BREAK CURRENTLY TRACKING ************************************************\n",
    "    #**************************************************************************************************************************\n",
    "    if key == ord('k'):\n",
    "        TRACKING_ON = 0\n",
    "        Tracker = cv2.MultiTracker_create() # clear tracking object\n",
    "    #**************************************************************************************************************************\n",
    "    \n",
    "    #************************************* SHOW GRID **************************************************************************\n",
    "    if (SHOW_GRID == 1):\n",
    "\n",
    "        height, width, channels = frame.shape\n",
    "        for x in range(0, width -1, GRID_SIZE):\n",
    "            cv2.line(frame, (x, 0), (x, height), (255, 255, 255), 1, 1)\n",
    "\n",
    "        for y in range(0, width -1, GRID_SIZE):\n",
    "            cv2.line(frame, (0, y), (width, y), (255, 255, 255), 1, 1)\n",
    "    \n",
    "    #************************************* SHOW VIDEO STREAM ******************************************************************\n",
    "       \n",
    "    if (SHOW_FPS == 1):\n",
    "        end = time.time()\n",
    "\n",
    "        frame_time = (end - start) + 0.0001\n",
    "        fps = np.floor(1/frame_time)\n",
    "\n",
    "        cv2.putText(frame, \"FPS: {}\".format(fps), (0, 430),cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 50, 50), 2)\n",
    "    \n",
    "    if (WATCH_FILTER != 1) & (WATCH_CANNY != 1):\n",
    "        cv2.imshow(\"ROI selector\", frame)\n",
    "    \n",
    "    if (WATCH_FILTER != 1) & (WATCH_CANNY == 1):\n",
    "        canny_h_concat = np.concatenate((frame, frame_canny_show), axis=1)\n",
    "        cv2.imshow(\"ROI selector\", canny_h_concat)\n",
    "        \n",
    "    if (WATCH_FILTER == 1) & (WATCH_CANNY != 1):\n",
    "        filter_h_concat = np.concatenate((frame, output_filter_show), axis=1)\n",
    "        cv2.imshow(\"ROI selector\", filter_h_concat)\n",
    "        \n",
    "    if (WATCH_FILTER == 1) & (WATCH_CANNY == 1):\n",
    "        watch_1 = np.concatenate((frame, output_filter_show), axis=0)\n",
    "        watch_2 = np.concatenate((frame_canny_show,  frame), axis=0)\n",
    "        all_watch = np.concatenate((watch_1, watch_2), axis=1)\n",
    "        cv2.imshow(\"ROI selector\", all_watch)\n",
    "    \n",
    "    #**************************************************************************************************************************    \n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
