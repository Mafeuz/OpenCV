{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: I. L. O. Bastos, M. F. Angelo and A. C. Loula, \"Recognition of Static Gestures Applied to Brazilian Sign Language (Libras),\n",
    "# \" 2015 28th SIBGRAPI Conference on Graphics, Patterns and Images, Salvador, 2015, pp. 305-312."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/Mafeus/Desktop/Git_Repos/OpenCV')\n",
    "import OpCV_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'C:/Users/Mafeus/Desktop/libras_dataset_mdp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_imgs = glob.glob(dataset_path + '/A/' + '*.png')\n",
    "B_imgs = glob.glob(dataset_path + '/B/' + '*.png')\n",
    "C_imgs = glob.glob(dataset_path + '/C/' + '*.png')\n",
    "D_imgs = glob.glob(dataset_path + '/D/' + '*.png')\n",
    "E_imgs = glob.glob(dataset_path + '/E/' + '*.png')\n",
    "F_imgs = glob.glob(dataset_path + '/F/' + '*.png')\n",
    "G_imgs = glob.glob(dataset_path + '/G/' + '*.png')\n",
    "I_imgs = glob.glob(dataset_path + '/I/' + '*.png')\n",
    "L_imgs = glob.glob(dataset_path + '/L/' + '*.png')\n",
    "M_imgs = glob.glob(dataset_path + '/M/' + '*.png')\n",
    "N_imgs = glob.glob(dataset_path + '/N/' + '*.png')\n",
    "O_imgs = glob.glob(dataset_path + '/O/' + '*.png')\n",
    "P_imgs = glob.glob(dataset_path + '/P/' + '*.png')\n",
    "Q_imgs = glob.glob(dataset_path + '/Q/' + '*.png')\n",
    "R_imgs = glob.glob(dataset_path + '/R/' + '*.png')\n",
    "S_imgs = glob.glob(dataset_path + '/S/' + '*.png')\n",
    "T_imgs = glob.glob(dataset_path + '/T/' + '*.png')\n",
    "U_imgs = glob.glob(dataset_path + '/U/' + '*.png')\n",
    "V_imgs = glob.glob(dataset_path + '/V/' + '*.png')\n",
    "W_imgs = glob.glob(dataset_path + '/W/' + '*.png')\n",
    "X_imgs = glob.glob(dataset_path + '/X/' + '*.png')\n",
    "Y_imgs = glob.glob(dataset_path + '/Y/' + '*.png')\n",
    "\n",
    "all_imgs = [A_imgs, B_imgs, C_imgs, D_imgs, E_imgs, F_imgs, G_imgs, I_imgs, L_imgs, M_imgs, N_imgs,\n",
    "            O_imgs, P_imgs, Q_imgs, R_imgs, S_imgs, T_imgs, U_imgs, V_imgs, W_imgs, X_imgs, Y_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_detection_no_scaled(results):\n",
    "    \n",
    "    for handLandmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "        landmarks_list = []\n",
    "            \n",
    "        for id, lm in enumerate(handLandmarks.landmark):\n",
    "            cX, cY  = lm.x, lm.y\n",
    "        \n",
    "            landmarks_list.append([id, cX, cY])\n",
    "                            \n",
    "        return landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A - 102 - 0.0 0.4243515 0.55601937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Letter Classification by getting Mediapipe Hand Detection Ouput Values:\n",
    "\n",
    "# Object Instances:\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpHands = mp.solutions.hands\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "for i, letter_imgs in enumerate(all_imgs):\n",
    "    \n",
    "    letter = letters[i]\n",
    "    \n",
    "    for j, img in enumerate(letter_imgs):\n",
    "        \n",
    "        read_img = cv2.imread(img)\n",
    "        \n",
    "        hands = mpHands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.4, min_tracking_confidence=0.4)\n",
    "        results = hands.process(cv2.cvtColor(read_img, cv2.COLOR_BGR2RGB))\n",
    "                \n",
    "        if results.multi_hand_landmarks:\n",
    "            lm = hand_detection_no_scaled(results)\n",
    "            \n",
    "            work_array = np.array([i, lm[0][1], lm[0][2], lm[1][1], lm[1][2], lm[2][1], lm[2][2],\n",
    "                                      lm[3][1], lm[3][2], lm[4][1], lm[4][2], lm[5][1], lm[5][2],\n",
    "                                      lm[6][1], lm[6][2], lm[7][1], lm[7][2], lm[8][1], lm[8][2],\n",
    "                                      lm[9][1], lm[9][2], lm[10][1], lm[10][2], lm[11][1], lm[11][2],\n",
    "                                      lm[12][1], lm[12][2], lm[13][1], lm[13][2], lm[14][1], lm[14][2],\n",
    "                                      lm[15][1], lm[15][2], lm[16][1], lm[16][2], lm[17][1], lm[17][2],\n",
    "                                      lm[18][1], lm[18][2], lm[19][1], lm[19][2], lm[20][1], lm[20][2],], dtype=np.float32)\n",
    "            \n",
    "            if (i == 0) & (j == 0) :\n",
    "                data_array = work_array.copy()\n",
    "            \n",
    "            if (j > 0):\n",
    "                data_array = np.vstack((data_array, work_array))\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            print(letter, '-', j, '-', work_array[0], work_array[1], work_array[21])\n",
    "            \n",
    "dataframe = pd.DataFrame(data_array)\n",
    "dataframe.to_csv('hands_dataframe', index=False)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
