{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libras (PTBR Hand Signal Language) Translation Video to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/google/mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/Mafeus/Desktop/Git_Repos/OpenCV')\n",
    "import OpCV_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.simpledialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_detection(frame, results, mpDraw, mpHands):\n",
    "    \n",
    "    for handLandmarks in results.multi_hand_landmarks:\n",
    "            \n",
    "        landmarks_list = []\n",
    "            \n",
    "        for id, lm in enumerate(handLandmarks.landmark):\n",
    "            h, w, c = frame.shape\n",
    "            cX, cY  = int(lm.x*w), int(lm.y*h)\n",
    "                \n",
    "            cv2.circle(frame, (cX, cY), 6, (205, 0, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, '{}'.format(id), (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 0, 0), 1)\n",
    "                \n",
    "            landmarks_list.append([id, cX, cY])\n",
    "            \n",
    "        mpDraw.draw_landmarks(frame, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "        mpDraw.draw_landmarks(bboard, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "                \n",
    "        return landmarks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server OFF\n"
     ]
    }
   ],
   "source": [
    "# Object Instances:\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpHands = mp.solutions.hands\n",
    "\n",
    "hands = mpHands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.4, min_tracking_confidence=0.4)\n",
    "hands_mirror = mpHands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.4, min_tracking_confidence=0.4)\n",
    "hands_rotated = mpHands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.4, min_tracking_confidence=0.4)\n",
    "\n",
    "thumb         = [1, 2, 3, 4]\n",
    "index_finger  = [5, 6, 7, 8]\n",
    "middle_finger = [9, 10, 11, 12]\n",
    "ring_finger   = [13, 14, 15, 16]\n",
    "pinky_finger  = [17, 18, 19, 20]\n",
    "\n",
    "main = tk.Tk()\n",
    "main.withdraw()\n",
    "\n",
    "# Load Video:\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture('http://192.168.0.14:8080/video')\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "img_libras = cv2.imread('libras.jpeg')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    os.chdir('C:/Users/Mafeus/Desktop/Git_Repos/OpenCV/Gesture Recognition/Libras Recognition Method')\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    success, frame = cap.read()\n",
    "            \n",
    "    if not success:\n",
    "        print('Server OFF')\n",
    "        break\n",
    "        \n",
    "    # Adjust Img from Camera\n",
    "    frame = cv2.resize(frame, (0,0), None, 0.3, 0.3)\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    frame = cv2.flip(frame, -1)\n",
    "                    \n",
    "    #####################################################################################################################\n",
    "    \n",
    "    results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    frame_mirror = cv2.flip(frame, 1)\n",
    "    results_mirror = hands_mirror.process(cv2.cvtColor(frame_mirror, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "    frame_rotated = OpCV_Utils.img_rotation(frame, random.randint(1,20), (frame.shape[1]//2, frame.shape[0]//2))\n",
    "    results_rotated = hands.process(cv2.cvtColor(frame_rotated, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    frame_to_save = frame.copy()\n",
    "    frame_mirror_to_save = frame_mirror.copy()\n",
    "    frame_rotated_to_save = frame_rotated.copy()\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        landmarks_list = hand_detection(frame, results, mpDraw, mpHands)\n",
    "        \n",
    "    if results_mirror.multi_hand_landmarks:\n",
    "        landmarks_list = hand_detection(frame_mirror, results_mirror, mpDraw, mpHands)\n",
    "        \n",
    "    if results_rotated.multi_hand_landmarks:\n",
    "        landmarks_list = hand_detection(frame_rotated, results_rotated, mpDraw, mpHands)\n",
    "                                \n",
    "    frame_stack = OpCV_Utils.stackImgs([[frame, frame_mirror, frame_rotated, img_libras]], scale = 0.8)\n",
    "                \n",
    "    #####################################################################################################################\n",
    "    \n",
    "    # Keyboard Controls:\n",
    "    \n",
    "    key = cv2.waitKey(1) or 0xff   \n",
    "        \n",
    "    if key == ord('k'):\n",
    "        break\n",
    "        \n",
    "    if key == ord('p'):       \n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    if key == ord('y'):\n",
    "        \n",
    "        try:\n",
    "            class_name = tkinter.simpledialog.askstring('Define Class', 'Define Class: ')\n",
    "            \n",
    "            folder_path = 'libras_dataset_mdp/A/'\n",
    "        \n",
    "            os.chdir(folder_path)\n",
    "\n",
    "            cv2.imwrite(class_name + '.png', frame_to_save)\n",
    "            cv2.imwrite(class_name + '_mirror.png', frame_mirror_to_save)\n",
    "            cv2.imwrite(class_name + '_rotated.png', frame_rotated_to_save)\n",
    "\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "        except:\n",
    "            print('Not Saved')\n",
    "       \n",
    "    end = time.time()\n",
    "\n",
    "    frame_time = (end - start) + 0.0001\n",
    "    fps = np.floor(1/frame_time)\n",
    "            \n",
    "    # cv2.putText(frame, \"FPS: {}\".format(fps), (9,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Output\", frame_stack)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
